# ï¿½ï¿½ Ollama Chat Client by Sun & Rain Works

A modern console-based chat client for Ollama, built with .NET 9 and Semantic Kernel. Experience natural conversations with advanced AI models through a sleek command-line interface.

## ğŸŒŸ Key Features

- ğŸ”„ Real-time streaming responses with token-by-token output
- ğŸ¨ Rich colored console interface for enhanced readability
- ğŸ“ Intelligent markdown code block handling
- ğŸ”Œ Seamless integration with Ollama API
- ğŸ›¡ï¸ Robust error handling and graceful degradation
- ğŸ§  Powered by Microsoft's Semantic Kernel
- ğŸ’¬ Full chat history support
- ğŸ¯ Support for multiple LLM models

## ğŸš€ Getting Started

### Prerequisites

- [.NET 9.0](https://dotnet.microsoft.com/download/dotnet/9.0)
- [Ollama](https://ollama.ai/download)
- Llama model installed: `bash
ollama pull llama3:latest  `

### ğŸ› ï¸ Quick Start

1. Clone and navigate: `bash
git clone https://github.com/sunandrain/ollama-chat-client.git
cd ollama-chat-client   `

2. Install dependencies: `bash
dotnet restore   `

3. Start Ollama server: `bash
ollama serve   `

4. Run the application: `bash
dotnet run   `

## ğŸ’¡ Usage Guide

### Basic Commands

- Type your message and press Enter to send
- Press Enter with empty input or type 'exit' to quit
- Messages are color-coded for better visualization:
  - ğŸŸ¢ User input (Green)
  - ğŸ”µ Assistant responses (Cyan headers)
  - ğŸ”´ Error messages (Red)
  - ğŸŸ¡ System messages (Yellow)

### Example Interaction
